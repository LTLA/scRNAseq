#' Upload a directory to the gypsum backend
#'
#' Upload a directory containing one or more datasets to the gypsum backend as a versioned asset.
#' This requires uploader permissions to the \pkg{scRNAseq} project.
#' 
#' @param dir String containing the path to a directory.
#' This can either be the same directory generated by \code{\link{saveDataset}}
#' or it can be a parent directory containing multiple subdirectories generated by \code{\link{saveDataset}}.
#' @param name String containing the name of the asset. 
#' This should not contain \code{/} or start with \code{..}.
#' @param version String containing the version of the asset. 
#' This should not contain \code{/} or start with \code{..}.
#' @param package String containing the package name.
#' @param url String containing the URL to the gypsum REST API.
#' @param probation Logical scalar indicating whether this should be a probational upload.
#' @param concurrent Integer scalar specifying the number of concurrent uploads.
#' @param abort.failed Logical scalar indicating whether to abort the upload on any failure.
#' Setting this to \code{FALSE} can be helpful for diagnosing upload problems.
#'
#' @return On successful upload, \code{NULL} is invisibly returned.
#'
#' @details
#' \code{dir} may contain multiple related datasets in subdirectories, 
#' generated by \code{\link{saveDataset}} calls on different \linkS4class{SummarizedExperiment} objects.
#' This is occasionally useful for studies with multiple outputs, e.g., for different species or modalities.
#'
#' The \code{probation} flag allows contributors to test their uploads 
#' and for the \pkg{scRNAseq} maintainers to review the content before approval.
#' Note that uploads from untrusted users are automatically probational so setting \code{probation=FALSE} is not explicitly required in such cases.
#'
#' @seealso
#' \code{\link{saveDataset}}, to save data to a directory.
#'
#' \code{\link{fetchDataset}}, to download an existing dataset into the current sesssion.
#'
#' @author Aaron Lun
#' @examples
#' library(SingleCellExperiment)
#' sce <- SingleCellExperiment(list(counts=matrix(rpois(1000, lambda=1), 100, 10)))
#' rownames(sce) <- sprintf("GENE_%i", seq_len(nrow(sce)))
#' colnames(sce) <- head(LETTERS, 10)
#'
#' meta <- createMetadata(
#'     title="My dataset",
#'     description="This is my dataset",
#'     taxonomy.id="10090",
#'     genome="GRCh38",
#'     sources=list(list(provider="GEO", id="GSE12345")),
#'     maintainer.name="Shizuka Mogami",
#'     maintainer.email="mogami.shizuka@765pro.com"
#' )
#' 
#' cache <- tempfile()
#' saveDataset(sce, cache, meta)
#'
#' version <- as.character(Sys.Date())
#' if (interactive()) {
#'     # Uploading a probational version for test purposes.
#'     uploadDirectory(cache, "test", version, probation=TRUE)
#'
#'     # Cleaning up after ourselves.
#'     gypsum::rejectProbation("scRNAseq", "test", version)
#' }
#'
#' @export
uploadDirectory <- function(dir, name, version, package="scRNAseq", url=NULL, probation=FALSE, concurrent=1, abort.failed=TRUE) {
    if (is.null(url)) {
        url <- gypsum::restUrl()
    }

    # Going through the directory contents and unpacking the explicit links.
    listing <- list_files(dir)

    blob <- gypsum::startUpload(
        project=package,
        asset=name,
        version=version, 
        files=data.frame(listing$files),
        links=data.frame(listing$links),
        directory=dir,
        probation=probation,
        url=url
    )

    success <- FALSE
    if (abort.failed) {
        on.exit({
            if (!success) {
                gypsum::abortUpload(blob)
            }
        })
    }

    gypsum::uploadFiles(blob, directory=dir, url=url, concurrent=concurrent)
    gypsum::completeUpload(blob, url=url)

    success <- TRUE
    invisible(NULL)
}

append_path_or_null <- function(dir, base) {
    if (is.null(dir)) {
        base
    } else {
        paste0(dir, "/", base)
    }
}

list_files <- function(full, relative=NULL, link=NULL) {
    # Handle ScrnaseqMatrix objects.
    collected <- list.files(full)
    if ("_link" %in% collected) {
        link <- jsonlite::fromJSON(file.path(full, "_link"), simplifyVector=FALSE)
        collected <- setdiff(collected, '_link')
    }

    out.links <- list(
        to.project=character(0), 
        to.asset=character(0),
        to.version=character(0),
        to.path=character(0),
        from.path=character(0)
    )

    out.files <- list(
        path=character(0),
        md5sum=character(0),
        size=numeric(0)
    )

    for (f in collected) {
        f2 <- file.path(full, f)
        r2 <- append_path_or_null(relative, f)
        stuff <- file.info(f2)

        if (stuff$isdir) {
            link2 <- link
            if (!is.null(link2)) {
                link2$path <- paste0(link2$path, "/", f)
            }
            x <- list_files(f2, r2, link=link2)
            for (n in names(out.links)) {
                out.links[[n]] <- c(out.links[[n]], x$links[[n]])
            }
            for (n in names(out.files)) {
                out.files[[n]] <- c(out.files[[n]], x$files[[n]])
            }

        } else if (is.null(link)) {
            out.files$path <- c(out.files$path, r2)
            out.files$md5sum <- c(out.files$md5sum, digest::digest(file=f2))
            out.files$size <- c(out.files$size, stuff$size)

        } else {
            out.links$from.path <- c(out.links$from.path, r2) 
            out.links$to.project <- c(out.links$to.project, link$project)
            out.links$to.asset <- c(out.links$to.asset, link$asset)
            out.links$to.version <- c(out.links$to.version, link$version)
            out.links$to.path <- c(out.links$to.path, append_path_or_null(link$path, f))
        }
    }

    list(links=out.links, files=out.files)
}
